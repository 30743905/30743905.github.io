<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[计算模型之Java8]]></title>
    <url>%2F2018%2F01%2F27%2F%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B%E4%B9%8BJava8%2F</url>
    <content type="text"><![CDATA[简述Java 8发行版是自Java 5（发行于2004，已经过了相当一段时间了）以来最具革命性的版本。Java 8我认为带来的最核心的变化主要体现在三个方面：Lambda(函数式编程)、Stream(流)和并发/并行编程简易化。其中Lamdba特性是最具革命性，为Stream、并行/并发编程等新特性提供基础支撑。 Java 8所做的改变，在许多方面比Java历史上任何一次改变都深远，为古老渐显疲态的Java注入新的活力：​ 1、lambda:最具革命性的新特性，直观上看：代码量大大减少，程序逻辑也清晰明了，可以编写出简单、干净、易读的代码；深层原因：函数式编程思想的风靡流行​ 2、Stream(流):Lambda和集合结合的产物，也让Lambda函数式编程这一酷炫技术得到很好展现的一个新特性， 是Java 8带给我们最核心、最实用的一个特性​ 3、并发/并行:借助于lambda、Stream和ForkJoin、CompletableFuture等新特性，让并发/并行编程更加简单 Lambda概述Lambda表达式并不是Java 8新出的概念，最近几年lambda表达式早已风靡于编程界，很多现代编程语言都把它作为函数式编程的基本组成部分，像Scala、Groovy等早已开始支持Lambda表达式语法。而且实践证明：让函数作为一等公民(Java是面向对象编程，只有对象是一等公民可以进行任意的传递，不过lambda底层实现依然采用的是对象封装实现的，因此，lambda可以看成是Java 8提供给程序员的一种”语法糖”)可以扩充程序员的工具库，从而让代码量大大减少、程序逻辑更清晰明了，编写出简单、干净、易读的代码，最终实现编程简单轻松和提高开发人员效率。 让Java实现一种尽可能轻量级的将代码封装为数据（Model code as data）的方法，这就是lambda表达式最本质的需求，用专家更精简的说法是：让行为参数化。 我们知道，Java作为一门面向对象的语言：在Java世界里，一切皆对象。在Java 8之前，Java专家们使用接口中的一个方法来封装对象行为进行参数传递，如可能存在如下情况： 12345button.addActionListener(new ActionListener) &#123; public void actionPerformed(ActionEvent e) &#123; ui.dazzle(e.getModifiers()); &#125;&#125; 使用接口方法定义行为，然后通过匿名类方式实现行为传递，但通常非常臃肿，既难于编写，也不易于维护。这种方案并不令人满意：冗余的语法会影响程序员在实践中使用行为参数化的积极性。像上面例子一样，真正有用的代码就只有一句：ui.dazzle(e.getModifiers())，而大量模板式的“噪点”代码充斥其中使代码复杂化，结构不够清晰。Java 8引入的lambda就是对这一问题很好的解决，通过向方法传递代码片段来解决这一问题，让你很简洁地对一个行为进行参数化并传递： 1button.addActionListener(e -&gt; ui.dazzle(e.getModifiers())) ###案例 123456789101112131415161718192021采用lambda可以轻松实现行为参数化，这样在接口设计的时候可以更抽象化、灵活性更高，如下： @Test public void test()&#123; System.out.println(operation((x,y)-&gt;x+y, 5));//实现累加求和 System.out.println(operation((x,y)-&gt;x*y, 5));//实现阶乘 System.out.println(operation((x,y)-&gt;x*x+y*y, 5));//实现其它需求 &#125; /** * 1、实现根据传入的n创建一个int类型序列：1,2,3,4...n * 2、将传入的行为函数去处理这个int类型序列 */ private int operation(IntBinaryOperator operator, int n)&#123; return IntStream.rangeClosed(1,n).reduce(operator).getAsInt(); &#125;通过使用lambda表达式，简单的几行代码就实现了一个灵活的数学运算方法，这就是lambda强大的地方。如果我们使用传统方式如何实现上述功能呢： 1、采用策略模式，首先定义一个接口，接口中定义一个方法代表数据处理的业务逻辑入口 2、执行运算的时候，通过匿名内部类将不同的业务逻辑封装到1步骤中定义的接口中，通过对象方式传入方法你可以自己用传统的策略模式实现上述功能，哪种方式编写简洁、灵活就一目了然了。 方法引用123456789101112131415161718192021222324若Lambda体中的内容有方法已经实现了，我们可以使用方法引用，可以理解为：方法引用是Lambda表达式的另外一种表现形式，对一类特殊的lambda表达式进一步进行简化。方法引用和下面的构造器引用都很简单，没什么实质性需要讲解的，本质上是对一类特殊的lambda进一步进行简化编写，可以看着是Java 8在极简编程方面的努力尝试。主要有三种语法格式： 1、对象::实例方法名 2、类::静态方法名 3、类:::实例方法名方法引用：lambda表达式参数类型和返回类型和引用方法的参数类型和返回类型一致//lamdba表达式方式Consumer&lt;String&gt; consumer = x -&gt; System.out.println(x);//方法引用方式consumer = System.out::print;//类::静态方法名Comparator&lt;Integer&gt; comparable = (x, y) -&gt; Integer.compare(x, y);comparable = Integer::compare;//类::实例方法名方式调用必须满足条件：两个参数，第一个参数是实例方法的调用者，而第二个参数是实例方法的参数时，即lamdba体中参数1.方法(参数2)，可以使用类::实例方法名//即：参数1作为调用方，参数2作为参数样式，也即，实例方法是参数1类型中的实例方法BiPredicate&lt;String,String&gt; bp = (x,y) -&gt; x.equals(y);bp = String::equals; 构造器引用1234567891011121314151617181920212223构造器引用，类似于方法引用:1、格式：ClassName::new2、与函数式接口相结合，自动与函数式接口中方法兼容。3、可以把构造器引用赋值给定义的方法，与构造器参数列表要与接口中抽象方法的参数列表一致class Employee&#123; public Employee(String str)&#123; System.out.println("str:"+str); &#125; public Employee()&#123; System.out.println("无参构造方法"); &#125;&#125;//构造器引用//构造器的参数列表要和Supplier中的T get()参数列表一致，所以调用的是无参构造方法Supplier&lt;Employee&gt; supplier = () -&gt; new Employee();supplier = Employee::new;//构造器的参数列表要和Function中的R apply(T t)参数列表一致，所以调用的是有参构造方法Function&lt;String,Employee&gt; fun1 = (x) -&gt; new Employee(x);Function&lt;String,Employee&gt; fun2 = Employee::new;fun2.apply("hah"); Stream概述lambda函数式编程完善了面向对象编程的不足，可以实现更抽象、更灵活的接口，从而让代码质量更加高效。对于lambda表达式我们理解到这点基本就足已，因为它还是比较简单的，真正核心的地方是lambda表达式与流式思想的结合。 Stream就是这样一个lambda表达式与流式思想的结合的产物，是lambda表达式作为流式思想实现的一个很好方案的展现。Stream的本质你可以这么理解：Stream就是将一系列lambda表达式进行串联形成一条数据处理流水线，实现通过各个lambda表达式间相互协作最终完成复杂的业务处理。Stream让传统的面向“存储” 的集合，具有了面向“计算”的能力。Java 8引入的Stream我认为是对开发人员来讲是实用性最好、使用率最高的一项特性，因为对数据集合的操作在日常开发中扮演着越来越重要的地位。 Stream意义传统的项目开发，基本上数据都会存储在关系型数据库如MySQL或Oracle中，利用关系型数据库提供的丰富内置函数，可以帮助完成各种数据处理工作，因此，传统的开发更多的是面向数据库编程。然后，现在是一个信息数据爆炸的时代，数据来源五花八门导致数据格式也不在是传统的以结构化数据为主的特点，而是非结构化、半结构化数据越来越多，这就对数据处理的需求更多、处理手段要更加灵活。而且数据规模越来越大，传统的关系型数据库已经无法满足需要，所以出现现在NoSQL遍地开花的局面。NoSQL数据库主要解决的核心关注点“海量数据存储和高效数据检索”，而和关系型数据库核心关注点“强一致性和强大的数据处理功能”是不一致的。这两方面的变化导致了现在越来越多的项目已将数据处理的需求移植到了程序开发中，数据处理和并发编程在日常开发中需求量大增。 传统的Java集合操作提供的API接口只有基本的功能性接口，比如：新增元素、删除元素、集合大小、集合iterator迭代，缺少面向实际业务层面更高层次的抽象接口，而Stream就是解决了传统集合操作的不足，使程序员得以站在更高的抽象层次上对集合进行操作。 Stream实现了类似SQL语法样式，使用声明式的类似描述性语言，有效帮助开发人员构建高质量、高性能的数据处理平台，挖掘出真正的商业价值，让“大数据”发挥出强大的威力。 案例12345678910111213141516171819202122232425262728293031323334案例一:下面的代码源自JDK中的Class类型（getEnclosingMethod方法），这段代码会遍历所有声明的方法，然后根据方法名称、返回类型以及参数的数量和类型进行匹配：for (Method method : enclosingInfo.getEnclosingClass().getDeclaredMethods()) &#123; if (method.getName().equals(enclosingInfo.getName())) &#123; Class&lt;?&gt;[] candidateParamClasses = method.getParameterTypes(); if (candidateParamClasses.length == parameterClasses.length) &#123; boolean matches = true; for (int i = 0; i &lt; candidateParamClasses.length; i += 1) &#123; if (!candidateParamClasses[i].equals(parameterClasses[i])) &#123; matches = false; break; &#125; &#125; if (matches) &#123; // finally, check return type if (method.getReturnType().equals(returnType)) &#123; return method; &#125; &#125; &#125; &#125;&#125;throw new InternalError("Enclosing method not found");通过使用流，我们不但可以消除上面代码里面所有的临时变量，还可以把控制逻辑交给类库处理。通过反射得到方法列表之后，我们利用 Arrays.stream将它转化为Stream，然后利用一系列过滤器去除类型不符、参数不符以及返回值不符的方法，然后通过调用findFirst 得到Optional&lt;Method&gt;，最后利用orElseThrow 返回目标值或者抛出异常。return Arrays.stream(enclosingInfo.getEnclosingClass().getDeclaredMethods()) .filter(m -&gt; Objects.equals(m.getName(), enclosingInfo.getName())) .filter(m -&gt; Arrays.equals(m.getParameterTypes(), parameterClasses)) .filter(m -&gt; Objects.equals(m.getReturnType(), returnType)) .findFirst() .orElseThrow(() -&gt; new InternalError("Enclosing method not found"));相对于未使用流的代码，这段代码更加紧凑，可读性更好，也不容易出错。 1234567891011121314151617181920212223242526272829303132333435363738394041案例二：基本集合操作案例(出至《Java8函数式编程》) Album：专辑，由若干曲目组成Track：曲目，专辑中的一支曲目现在要实现这样需求：现在要找出长度大于1分钟的曲目，并将曲目名字返回成一个Set集合传统方式：public Set&lt;String&gt; findLongTracks(List&lt;Album&gt; albums) &#123; Set&lt;String&gt; trackNames = new HashSet&lt;&gt;(); for(Album album : albums) &#123; for (Track track : album.getTrackList()) &#123; if (track.getLength() &gt; 60) &#123; String name = track.getName(); trackNames.add(name); &#125; &#125; &#125; return trackNames;&#125;使用Stream方式：public Set&lt;String&gt; findLongTracks(List&lt;Album&gt; albums) &#123; return albums.stream() .flatMap(album -&gt; album.getTracks()) .filter(track -&gt; track.getLength() &gt; 60) .map(track -&gt; track.getName()) .collect(toSet());&#125;对比总结： 1、代码量减少 2、结构更加清晰，一方面是收益于代码量的减少；另一方面，主要是使用类似描述性语言让代码的逻辑更加清晰。比如看到filter就晓得是进行过滤处理，看到map就晓得是一对一处理、看到collect就晓得是将流收集到集合中等等，这些接口本身就具有很强的描述性，简化了开发人员对代码的理解 flatMap、filter、map、collect等等，这些就是Stream提供的声明式的类似描述性语言的API接口，搞过Spark开发的人看着这些函数名称应该很熟悉了，和Spark编程提供的算子很类似，在语义上基本一致，对大数据开发人员具有很好的亲和力。仔细思考会发现它们在计算模型设计的思想有很多的相似性： 1、Spark中对数据集封装成RDD，然后使用一堆map、flatMap、filter等算子对RDD中的数据元素进行中间层处理，最后使用reduce、count、collect、foreach等聚合操作输出最终结果； 2、Java 8中使用Stream对数据集进行封装，使用map、flatMap、filter等lambda表达式对Stream中元素进行中间层处理，最后使用reduce、count、collect、foreach等lambda表达式进行结果的聚合输出。 3、而且中间层map、flatMap、filter等操作它们都具有惰性特性，只有在遇到需要对结果进行聚合输出时才会正在的执行。 当然了这里只是列举的Spark Core编程思想，Spark还提供了Spark SQL、Spark Stream、Spark MLlib等模块，提供了大数据“一站式”的基于分布式的解决方案，显然是Stream无法比拟的。但是parallel和sequential可轻易的让Stream在并行流和串行流之间进行转换，也提供了丰富的“算子”操作，因此，你也可以把Stream看着是“轻量级”、“单机版”的Spark编程框架实现。 进一步延伸 Storm中的Bolt、Spark中的算子和Java 8中的lambda，它们的思想和UNIX中的管道、责任链和pipeline模式中封装的处理单元是很类似的：对数据的处理封装成一个个处理单元，然后根据业务需要组装成一个线性或非线性链表或DAG(有向无环图)，让数据像水流一样沿着这个有向无环图经过处理单元进行层层过滤、处理。这是一种非常实用的经典计算模型或叫编程思想，有一句话很能体现这种思想的价值：“如果说Unix是计算机文明中最伟大的发明，那么，Unix下的Pipe管道就是跟随Unix所带来的另一个伟大的发明”。它体现的哲学思想：”Do one thing, Do it well”，程序应该只关注一个目标，并尽可能把它做好，让程序能够互相协同工作完成复杂任务。 Storm、Spark计算模型的强大以及Java 8中lamdba简洁性，让我们看到：虽然它们和传统的管道、责任链、Pipeline等模式在底层思想上如此的一致，但是在技术上还是向前迈出了很大一步，这就是技术积累进步的力量。 也再次印证了：火热的大数据时代让这一编程思想再次受到人们的关注，Java 8中及时引入lambda函数式编程，不在简简单单认为只是一种酷炫、装逼神器，而是一种迫切的真实需求体现，是顺应潮流的必然结果。 声明式编程一般通过编程实现一个系统，有两种思考方式。一种专注于如何实现，比如：“首先做这个，紧接着更新那个，然后……”举个例子，如果你希望通过计算找出列表中最昂贵的事务，通常需要执行一系列的命令：从列表中取出一个事务，将其与临时最昂贵事务进行比较；如果该事务开销更大，就将临时最昂贵的事务设置为该事务；接着从列表中取出下一个事务，并重复上述操作。这种“如何做”风格的编程非常适合经典的面向对象编程，有些时候我们也称之为“命令式”编程，因为它的特点是它的指令和计算机底层的词汇非常相近，比如赋值、条件分支以及循环，就像下面这段代码： 1234567891011Transaction mostExpensive = transactions.get(0);if(mostExpensive == null) throw new IllegalArgumentException("Empty list of transactions")for(Transaction t: transactions.subList(1, transactions.size()))&#123; if(t.getValue() &gt; mostExpensive.getValue())&#123; mostExpensive = t; &#125;&#125;另一种方式则更加关注要做什么。使用Stream API你可以指定下面这样的查询：Optional&lt;Transaction&gt; mostExpensive = transactions.stream().max(comparing(Transaction::getValue)); 这个查询把最终如何实现的细节留给了函数库。我们把这种思想称之为内部迭代。它的巨大优势在于你的查询语句现在读起来就像是问题陈述，由于采用了这种方式，我们马上就能理解它的功能，比理解一系列的命令要简洁得多。 采用这种“要做什么”风格的编程通常被称为声明式编程。你制定规则，给出了希望实现的目标，让系统来决定如何实现这个目标。它带来的好处非常明显，用这种方式编写的代码更加接近问题陈述了。 在声明式编程语言中最为我们所熟知的是SQL，这个被称为第三代半或第四代编程语言取得了巨大成功，很重要的一点：它可以使用声明式语言，而不必关注具体实现细节。这一特性让它的使用及其简单，也成为它广受欢迎的关键。 Stream遵循”做什么，而不是怎么去做”的原则，可以看成lambda函数式编程对声明式编程的具体实践：你只需要使用不相互影响的表达式，描述想要做什么，由系统来选择如何实现。你可以使用Stream将几个操作串接在一起，表达一个复杂的操作，这些都是函数式编程语言的特性。 并行流并行化操作流只需改变一个方法调用。如果已经有一个Stream对象，调用它的parallel方法就能让其拥有并行操作的能力。如果想从一个集合类创建一个流，调用parallelStream就能立即获得一个拥有并行能力的流，非常的简单就实现了并行化编程。并行流就是一个把内容分成多个数据块，并用不同的线程分别处理每个数据块的流。这样一来，你就可以自动把给定操作的工作负荷分配给多核处理器的所有内核，让他们都忙起来。 并行流内部使用了默认的ForkJoinPool，它默认的线程数量就是你的处理器数量，这个值是由Runtime.getRuntime().availableProcessors()得到的。但是你可以通过系统属性java.util.concurrent.ForkJoinPool.common.parallelism来改变线程池大小，如下所示：System.setProperty(“java.util.concurrent.ForkJoinPool.common.parallelism”,”12”);这是一个全局设置，因此它将影响代码中所有的并行流。反过来说，目前还无法专为某个并行流指定这个值。一般而言，让ForkJoinPool的大小等于处理器数量是个不错的默认值，除非你有很好的理由，否则我们强烈建议你不要修改它。 当然，也可以通过自定义ForkJoinPool并指定并行度方式实现局部并行度修改，方式如下： 1234567891011121314public void test() throws Exception &#123; ForkJoinPool pool = new ForkJoinPool(6);//指定并行度为6，下面并行流执行的时并行度即设置成6 Long ret = pool.submit(() -&gt; &#123; return LongStream.range(1, 100).boxed().collect(Collectors.toList()) .stream() .parallel() .map(x -&gt; &#123; System.out.println(Thread.currentThread().getName()+":"+x); return x * 2; &#125;) .reduce((x, y) -&gt; x + y) .get(); &#125;).get(); &#125; 这是一个多核的时代，并行流对提系统整体升性能是极具价值，最关键的是并行流和串行流间切换如此的简单，一个函数就可搞定，这是传统Java进行并行编程无法想象的。 Stream总结java 8的流式处理极大的简化了对于集合的操作，实际上不光是集合，包括数组、文件等，只要是可以转换成流，我们都可以借助流式处理，类似于我们写SQL语句一样对其进行操作。java 8通过内部迭代来实现对流的处理，一个流式处理可以分为三个部分：转换成流、中间操作、终端操作。它们之间的区别就是：中间操作输出还是流，一般是用于对流中元素进行处理，而终端操作一般是聚合操作，用于获取最终的结果。如下图： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134下面再通过一个案例再次体验下并行/并发编程方面Stream和传统编程巨大的区别蒙特卡洛模拟案例(出至《Java8函数式编程》)如果公平地掷两次骰子，然后将赢的一面上的点数相加，就会得到一个2~12的数字。点数的和至少是2，因为骰子六个面上最小的点数是1，而我们将骰子掷了两次；点数的和最大超不过12，因为骰子点数最多的一面也不过6点。我们想要得出点数落在2~12之间每个值的概率。 方式一：求出掷骰子的所有组合，比如，得到2点的方式是第一次掷得1点，第二次也掷得1点。总共有36种可能的组合，因此，掷得2点的概率就是1/36。方式二：使用1到6的随机数模拟掷骰子事件，然后用得到每个点数的次数除以总的投掷次数。这就是一个简单的蒙特卡洛模拟。模拟投掷骰子的次数越多，得到的结果越准确，因此，我们希望尽可能多地增加模拟次数(Spark案例中SparkPi，就是利用蒙特卡洛模拟求π值)。 /** * 模拟公平投掷两次筛子，赢面上点数和 * @return */ private int twoDiceThrows() &#123; ThreadLocalRandom random = ThreadLocalRandom.current(); int firstThrow = random.nextInt(1, 7); int secondThrow = random.nextInt(1, 7); return firstThrow + secondThrow; &#125; /** * 使用蒙特卡洛模拟法并行化模拟掷骰子事件 */ public Map&lt;Integer, Double&gt; parallelDiceRolls(int N) &#123; double fraction = 1.0 / N; return IntStream.range(0, N).parallel() .mapToObj(x -&gt; twoDiceThrows()) .collect(Collectors.groupingBy(side -&gt; side, Collectors.summingDouble(n -&gt; fraction))); //Collectors.summingDouble(n -&gt; fraction) 将n转成double类型fraction，并累加 &#125; public static void main(String[] args) &#123; Map&lt;Integer, Double&gt; ret = new Demo1().parallelDiceRolls(10000); ret.forEach((k,v) -&gt; System.out.println("点数:"+k+", 概率"+v)); &#125;输出结果： 点数:2, 概率0.027693 点数:3, 概率0.05557999999999999 点数:4, 概率0.083445 点数:5, 概率0.11120599999999999 点数:6, 概率0.139088 点数:7, 概率0.166841 点数:8, 概率0.138882 点数:9, 概率0.11072699999999999 点数:10, 概率0.083487 点数:11, 概率0.055407 点数:12, 概率0.027644使用传统方式实现上述同样效果代码：/** * @author 36410 * @Copyright © 2017 tiger Inc. All rights reserved. * @create 2017-12-01 17:11 * Description:通过手动使用线程模拟掷骰子事件 */public class ManualDiceRolls &#123; private static final int N = 100000000; private final double fraction; private final Map&lt;Integer, Double&gt; results; private final int numberOfThreads; private final ExecutorService executor; private final int workPerThread; public static void main(String[] args) &#123; ManualDiceRolls roles = new ManualDiceRolls(); roles.simulateDiceRoles(); &#125; public ManualDiceRolls() &#123; fraction = 1.0 / N; results = new ConcurrentHashMap&lt;&gt;(); numberOfThreads = Runtime.getRuntime().availableProcessors(); executor = Executors.newFixedThreadPool(numberOfThreads); workPerThread = N / numberOfThreads; &#125; public void simulateDiceRoles() &#123; List&lt;Future&lt;?&gt;&gt; futures = submitJobs(); awaitCompletion(futures); printResults(); &#125; private void printResults() &#123; results.entrySet() .forEach(System.out::println); &#125; private List&lt;Future&lt;?&gt;&gt; submitJobs() &#123; List&lt;Future&lt;?&gt;&gt; futures = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; numberOfThreads; i++) &#123; futures.add(executor.submit(makeJob())); &#125; return futures; &#125; private Runnable makeJob() &#123; return () -&gt; &#123; ThreadLocalRandom random = ThreadLocalRandom.current(); for (int i = 0; i &lt; workPerThread; i++) &#123; int entry = twoDiceThrows(random); accumulateResult(entry); &#125; &#125;; &#125; private void accumulateResult(int entry) &#123; results.compute(entry, (key, previous) -&gt; previous == null ? fraction : previous + fraction ); &#125; private int twoDiceThrows(ThreadLocalRandom random) &#123; int firstThrow = random.nextInt(1, 7); int secondThrow = random.nextInt(1, 7); return firstThrow + secondThrow; &#125; private void awaitCompletion(List&lt;Future&lt;?&gt;&gt; futures) &#123; futures.forEach((future) -&gt; &#123; try &#123; future.get(); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;); executor.shutdown(); &#125;&#125;对比： 1、使用Stream几行代码就可以搞定一个复杂的并发编程，而使用传统方式却需要几十行到上百行等，代码的简洁性体现的淋漓尽致 2、得益于Stream编程使代码量大大减少，同时采用的是声明式编程，采用Stream编程方式结构流程清晰明了，而使用传统方式构建的程序流程就不是那么容易理解了 3、对集合执行操作流水线，并可以通过简单的一个方法就实现了串行流与并行流间的切换，基本上不会付出任何代价，传统方式在并发编程方面，又是创建管理线程池、又是要创建管理线程、最后通过异步方式获取结果等，显然代价要昂贵的多，这也是体现出传统编程下对使用并发编程积极性不高的一个因数，然而在当代这个多核时代，为了尽可能发挥出多核硬件资源的优势，并发编程是不可避免的，而且重要性也会越来越高 Stream性能分析Stream接口可以让你不用太费力气就能对数据集执行并行操作。它允许你声明性地将顺序流变为并行流。可以通过对收集源调用parallelStream方法来把集合转换为并行流。并行流就是一个把内容分成多个数据块，并用不同的线程分别处理每个数据块的流。这样一来，你就可以自动把给定操作的工作负荷分配给多核处理器的所有内核，让它们都忙起来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121案例：累加求和方式一：传统方式 public long iterativeSum(long n) &#123; long result = 0; for (long i = 1L; i &lt;= n; i++) &#123; result += i; &#125; return result; &#125;方式二：串行流方式 public long sequentialSum(long n) &#123; return Stream.iterate(1L, i -&gt; i + 1) .limit(n) .reduce(0L, Long::sum); &#125;方式三：并行流方式 public long parallelSum(long n) &#123; return Stream.iterate(1L, i -&gt; i + 1) .limit(n) .parallel() .reduce(0L, Long::sum); &#125;使用parallel()可以把流转换成并行流，从而让前面的函数归约过程（也就是求和）并行运行。Stream在内部分成了几块。因此可以对不同的块独立并行进行归纳操作，最后，同一个归纳操作会将各个子流的部分归纳结果合并起来，得到整个原始流的归纳结果。 配置并行流使用的线程池看看流的parallel方法，你可能会想，并行流用的线程是从哪儿来的？有多少个？怎么自定义这个过程呢？并行流内部使用了默认的ForkJoinPool，它默认的线程数量就是你的处理器数量， 这个值是由Runtime.getRuntime().availableProcessors()得到的。但是你可以通过系统属性java.util.concurrent.ForkJoinPool.common.parallelism来改变线程池大小，如下所示：System.setProperty("java.util.concurrent.ForkJoinPool.common.parallelism","12");这是一个全局设置，因此它将影响代码中所有的并行流。反过来说，目前还无法专为某个并行流指定这个值。一般而言，让ForkJoinPool的大小等于处理器数量是个不错的默认值，除非你有很好的理由，否则我们强烈建议你不要修改它。 我们声称并行求和方法应该比顺序和迭代方法性能好。然而在软件工程上，靠猜绝对不是什么好办法！特别是在优化性能时，你应该始终遵循三个黄金规则：测量，测量，再测量。为此，你可以开发一个方法，如下所示(调用10次，取耗时最短一次)： public long measureSumPerf(Function&lt;Long, Long&gt; adder, long n) &#123; long fastest = Long.MAX_VALUE; for (int i = 0; i &lt; 10; i++) &#123; long start = System.nanoTime(); long sum = adder.apply(n); long duration = (System.nanoTime() - start) / 1_000_000; System.out.println("Result: " + sum); if (duration &lt; fastest) fastest = duration; &#125; return fastest; &#125;测试一：for循环原生类型： public long iterativeSum1(long n) &#123; long result = 0; for (long i = 1L; i &lt;= n; i++) &#123; result += i; &#125; return result; &#125;输出内容：for -&gt; 原生类型耗时(毫秒):5 测试二：for循环装箱类型：public long iterativeSum2(Long n) &#123; Long result = 0L; for (Long i = 1L; i &lt;= n; i++) &#123; result += i; &#125; return result; &#125;输出内容：for -&gt; 装箱类型耗时(毫秒):126 测试三：iterator串行 public long sequentialSum(long n) &#123; return Stream.iterate(1L, i -&gt; i + 1) .limit(n) .reduce(0L, Long::sum); &#125;输出内容：iterator -&gt; 串行(毫秒):118测试四：iterator并行 public long parallelSum(long n) &#123; return Stream.iterate(1L, i -&gt; i + 1) .limit(n) .parallel() .reduce(0L, Long::sum); &#125;输出内容：iterator -&gt; 并行(毫秒):308测试五：LongStream.rangeClosed串行 public static long rangedSum(long n) &#123; return LongStream.rangeClosed(1, n) .reduce(0L, Long::sum); &#125;输出内容：LongStream.rangeClosed -&gt; 串行(毫秒):4 测试六：LongStream.rangeClosed并行 public static long parallelRangedSum(long n) &#123; return LongStream.rangeClosed(1, n) .parallel() .reduce(0L, Long::sum); &#125;输出内容：LongStream.rangeClosed -&gt; 并行(毫秒):1 结果分析： 1、测试一和测试二对比：5ms VS 126 ms 分析：a.同是for循环累加求和操作，原生类型和装箱类型耗时相差几十倍，因为装箱的对象必须拆箱成数字才能求和，存在性能消耗 b.原生类型long占用8字节，而它的装箱类型是一个对象，对象在内存中存储的布局可以分为三块区域：对象头、实例数据和对齐填充，以64位JVM为例，装箱Long占用16+8=24字节，刚好是对齐不需要进行填充，可见Long装箱类型是原生类型long在内存占用上相差3倍，而Integer装箱类型和int原生类型相差6倍 c.从上面两点分析可以得出：在进行大量数据处理的时候，可以使用原生类型尽量使用原生类型，而不要使用装箱类型，不论在性能还是内存占用上，原生类型都极具优势 2、测试三和测试四对比：118ms VS 308ms 分析：看到这个结果，可能感到很惊讶，为什么并行流比串行流性能低那么多，按道理并行流应该比串行流快很多才符合逻辑。 原因：采用Stream.iterate()生成的流是没法分成多个独立块来并行执行，因为每次应用这个函数都要依赖前一次应用的结果，导致数据集合在归纳过程开始时是没有准备好的，因而无法有效地把流划分为小块来并行处理。但是把流标记成并行，你其实是给顺序处理增加了开销，它还要把每次求和操作分到一个不同的线程上。这就说明了并行编程可能很复杂，有时候甚至有点违反直觉。如果用得不对（比如采用了一个不易并行化的操作，如iterate），它甚至可能让程序的整体性能更差，所以在调用那个看似神奇的parallel操作时，了解背后到底发生了什么是很有必要的 3、测试一和测试四对比：5ms VS 118ms 分析：为什么采用Stream方式累加求和竟比传统for循环方式性能低那么多，相差几十倍 原因：采用Stream.iterate()生成流中元素是装箱类型，计算时要进行拆箱后才会进行累加求和计算，导致了性能差。从另一点也可以印证这个观点：测试2采用for循环装箱类型耗时126ms基本接近Stream.iterate()串行流性能，可见性能的差距主要体现在拆箱上面 4、测试五和测试三、测试一对比：4ms VS 118ms VS 5ms 分析：测试五性能要比测试三性能高很多 原因：a.Java8意识到原生类型和装箱类型性能差距的问题，因此提供了一些列直接生成原生类型的流的类，如LongStream、IntegerStream等，通过LongStream.rangeClosed()直接产生原生类型long，而不再是装箱类型Long b.测试五和测试一性能基本接近，这也说明采用Stream这套接口开发在给我们带来方便的同时，性能是没有打折的 5、测试六和测试五对比：1ms VS 4ms 分析：测试六采用并行流，并行流使用系统内置的ForkJoinPool线程池，线程数默认是Runtime.getRuntime().availableProcessors()，我当前硬件平台是4核，而这里任务是CPU密集型而非IO密集型，所以相差4倍符合预期。 并发/并行编程由于摩尔定律在处理器的时钟频率不断提升这一方式遇到了瓶颈，即单核CPU在性能上无法进一步获得有效提升，现在趋势是在横向上进行扩展，即无法获取更快的CPU核心，但是可以通过获取更多的CPU核心来提升性能，这就是所谓的多核时代的来临。由单核主频的提升到多核扩展这一硬件结构的转变，为了让你的代码运行得更快，需要你的代码具备并行运算的能力，可以让每个处理线程单独占据一个核，从而得到多倍的整体性能。 前面提到的并行流就是Java 8对并行编程一个很好的实践，但流类库提供的数据并行化只是其中的一种形式，下面会介绍Java 8在中并发/并行编程的其它手段。 并发/并行编程区别并发是两个任务共享时间段，并行则是两个任务在同一时间发生，比如运行在多核CPU上。如果一个程序要运行两个任务，并且只有一个CPU 给它们分配了不同的时间片，那么这就是并发，而不是并行。两者之间的区别如下图： CompletableFutureFuture接口是在Java5中被引入，设计初衷是对将来某个时刻会发生的结果进行建模，它建模了一种异步计算，返回一个执行运算结果的引用，当运算结束后，这个引用被返回给调用方。打个比方，你可以把它想象成这样的场景：你拿了一袋子衣服到你中意的干洗店去洗。干洗店的员工会给你张发票，告诉你什么时候你的衣服会洗好（这就是一个Future事件）。衣服干洗的同时，你可以去做其他的事情。Future的另一个优点是它比更底层的Thread更易用。要使用Future，通常你只需要将耗时的操作封装在一个Callable对象中，再将它提交给ExecutorService，就万事大吉了。下面这段代码展示了Java 8之前使用Future的一个例子。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849ExecutorService executor = Executors.newCachedThreadPool();Future&lt;Double&gt; future = executor.submit(new Callable&lt;Double&gt;() &#123; public Double call() &#123; return doSomeLongComputation(); &#125;&#125;);doSomethingElse();try &#123; Double result = future.get(1, TimeUnit.SECONDS);&#125; catch (ExecutionException ee) &#123; // 计算抛出一个异常&#125; catch (InterruptedException ie) &#123; // 当前线程在等待过程中被中断&#125; catch (TimeoutException te) &#123; // 在Future对象完成之前超过已过期&#125;我们很难表述Future结果之间的依赖性；从文字描述上这很简单，“当长时间计算任务完成时，请将该计算的结果通知到另一个长时间运行的计算任务，这两个计算任务都完成后，将计算的结果与另一个查询操作结果合并”。但是，使用Future中提供的方法完成这样的操作又是另外一回事。这也是我们需要更具描述能力的特性的原因，比如下面这些。 1、将两个异步计算合并为一个——这两个异步计算之间相互独立，同时第二个又依赖于第一个的结果 2、等待Future集合中的所有任务都完成 3、仅等待Future集合中最快结束的任务完成（有可能因为它们试图通过不同的方式计算同一个值），并返回它的结果 4、通过编程方式完成一个Future任务的执行（即以手工设定异步操作结果的方式） 5、应对Future的完成事件（即当Future的完成事件发生时会收到通知，并能使用Future计算的结果进行下一步的操作，不只是简单地阻塞等待操作的结果）。CompletableFuture类（它实现了Future接口）如何利用Java 8的新特性以更直观的方式将上述需求都变为可能。Stream和CompletableFuture的设计都遵循了类似的模式：它们都使用了Lambda表达式以及流水线的思想。从这个角度，你可以说CompletableFuture和Future的关系就跟Stream和Collection的关系一样。使用CompletableFuture很容易就构造出一个异步方法，而Java 8之前只能面向接口Callable构造，如果存在多个异步方法，就需要定义构造多个Callable接口的实现类，显然要繁琐很多： public Future&lt;Double&gt; getPriceAsync(String product) &#123; CompletableFuture&lt;Double&gt; futurePrice = new CompletableFuture&lt;&gt;(); new Thread( () -&gt; &#123; try &#123; double price = calculatePrice(product); futurePrice.complete(price);//如果价格计算正常结束，完成Future操作并设置商品价格 &#125; catch (Exception ex) &#123; futurePrice.completeExceptionally(ex);//否则就抛出导致失败的异常，完成这次Future操作 &#125; &#125;).start(); return futurePrice; &#125;我们已经了解了如何通过CompletableFuture编程方式构建异步方法，看起来这些操作也比较方便，但还有进一步提升的空间，CompletableFuture类自身提供了大量精巧的工厂方法，使用这些方法能更容易地完成整个流程，还不用担心实现的细节。比如，可以将上面的代码进一步简化： public Future&lt;Double&gt; getPriceAsync(String product) &#123; return CompletableFuture.supplyAsync(() -&gt; calculatePrice(product)); &#125;从这里再次见识到：Java 8在代码简洁性上做的比之前优秀太多了，lambda让行为参数化后，基本上模板化的代码都被封装起来了，开发人员只需关注真正与业务相关的核心代码片段即可，在提高代码开发效率的同时，代码质量也得到了很大提升。这就得益于声明式编程，你只需要关注你要做什么，而无需关注怎么做，具体实现的细节都被封装到框架中了，自然你的代码质量也就提升了。 Stream与CompletableFuture结合案例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758案例：最佳价格查询器(案例来源《Java8 实战》) 需求：现在有个商家列表，你需要实现一个方法，它接受产品名作为参数，返回一个字符串列表，这个字符串列表中包括商店的名称、该商店中指定商品的价格：商家列表：List&lt;Shop&gt; shops = Arrays.asList(new Shop("BestPrice"), new Shop("LetsSaveBig"), new Shop("MyFavoriteShop"), new Shop("BuyItAll"));方式一：采用顺序查询所有商店的方式实现的findPrices方法public List&lt;String&gt; findPrices(String product) &#123; return shops.stream() .map(shop -&gt; String.format("%s price is %.2f", shop.getName(), shop.getPrice(product))) .collect(toList());&#125;方式二：对findPrices进行并行操作public List&lt;String&gt; findPrices(String product) &#123; return shops.parallelStream() .map(shop -&gt; String.format("%s price is %.2f", shop.getName(), shop.getPrice(product))) .collect(toList());&#125;假如商家查询价格是个比较耗时的接口，可能也是最快的改善方法是使用并行流来避免顺序计算。但是注意：Stream并行流使用的是内置的ForkJoinPool连接池中的执行线程（Executor）运行，直线线程默认等于CPU核数，如果商家列表比较多且查询价格接口存在IO阻塞情况，使用并行流并不能完全利用好CPU资源，当然也可以修改线程数使线程数加大，但是这个修改是全局性的，所以一般是不建议修改的，毕竟全局性的修改可能会导致对其它地方的使用造成影响。这就是为什么Stream叫做并行流而不是并发流。 方式三：使用CompletableFuture发起异步请求//自定义线程池执行器private final Executor executor = Executors.newFixedThreadPool(Math.min(shops.size(), 100), new ThreadFactory() &#123; public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setDaemon(true); return t; &#125; &#125;); public List&lt;String&gt; findPrices(String product) &#123; List&lt;CompletableFuture&lt;String&gt;&gt; priceFutures = shops.stream() .map(shop -&gt; CompletableFuture.supplyAsync( () -&gt; shop.getName() + " price is " + shop.getPrice(product)), executor)//这里需要指定使用的线程池，如果不指定，默认也是使用ForkJoinPool线程池 .collect(Collectors.toList()); return priceFutures.stream() .map(CompletableFuture::join) .collect(toList()); &#125;&#125;并行——使用流还是CompletableFutures？目前为止，你已经知道对集合进行并行计算有两种方式： 1、要么将其转化为并行流，利用map这样的操作开展工作 2、要么枚举出集合中的每一个元素，创建新的线程，在CompletableFuture内对其进行操作。后者提供了更多的灵活性，你可以调整线程池的大小，而这能帮助你确保整体的计算不会因为线程都在等待I/O而发生阻塞。 我们对使用这些API的建议如下。 1、如果你进行的是计算密集型的操作，并且没有I/O，那么推荐使用Stream接口，因为实现简单，同时效率也可能是最高的（如果所有的线程都是计算密集型的，那就没有必要创建比处理器核数更多的线程）。 2、反之，如果你并行的工作单元还涉及等待I/O的操作（包括网络连接等待），那么使用CompletableFuture灵活性更好，你可以像前文讨论的那样，依据等待计算，或者W/C的比率设定需要使用的线程数。 3、CompletableFuture具有一定的优势，因为它允许你对执行器（Executor）进行配置，尤其是线程池的大小，让它以更适合应用需求的方式进行配置，满足程序的要求，而这是并行流API无法提供的。让我们看看你怎样利用这种配置上的灵活性带来实际应用程序性能上的提升。 CompletableFuture实现多个异步任务流水线式操作12345678910111213141516171819202122232425262728上面介绍的主要是通过CompletableFuture及内置大量的工厂方法方便的实现异步接口，并结合Stream技术实现并发/并行编程，CompletableFuture实现的异步操作都是单任务操作。CompletableFuture类实现了CompletionStage和Future两个接口，一方面对传统的Future接口进行了增强，上面介绍的主要就是集中这个方面。下面就重点看下CompletionStage这个接口，它将流式思想引入到了并发/并行编程，让并发/并行编程具有了类似Stream的流水式操作的强大和灵活性，同时也降低了并发/并行编程的复杂性，这才是Java 8和之前并发/并行编程的一个本质区别。 需求描述： 1、任务1获取商品价格，任务2获取货币汇率，然后将任务1获取的商品价格*任务2获取的货币汇率相乘即可得到最终结果 2、任务1和任务2相互之间不存在依赖关系，所以任务1和任务2可以同时并行执行 3、任务1和任务2结果都出来后，才执行它们结果相乘得到最终结果Future&lt;Double&gt; futurePriceInUSD = CompletableFuture.supplyAsync(() -&gt; shop.getPrice(product)) .thenCombine(CompletableFuture.supplyAsync(() -&gt; exchangeService.getRate(Money.EUR, Money.USD)) , (price, rate) -&gt; price * rate);需求描述： 1、任务1是将数据写入数据库 2、任务2是将数据推送到第三方接口 3、任务1和任务2没有任何依赖关系，可以并行执行，通过join保证这两个任务都执行完成后才继续向下执行，如果不需要也可以不使用join进行阻塞CompletableFuture.runAsync(() -&gt; writeDb(alarmData), cachedThreadPool)//写入DB .runAsync(() -&gt; transferParallel(alarmData, uidSet), cachedThreadPool)//传送到推送服务器 .join();//阻塞直到上面2个任务执行完毕需求描述： 1、task1和task2同时并行执行，哪个执行快使用哪个的计算结果String result = CompletableFuture.supplyAsync(() -&gt; doTask1()) .applyToEither(CompletableFuture.supplyAsync(() -&gt; doTask2()), s -&gt; s) .join();CompletableFuture类提供了将两个CompletableFuture建立联系功能，通过迭代方式，可以让更多个CompletableFuture建立起关系，构建出更加复杂的业务逻辑，这就形成了类似Stream流式处理功能，只不过它内部元素不再是数据，而是一个个异步任务，而且通过内部抽象出来的语义接口，可以灵活实现这些异步任务间的依赖关系等，这就是流式编程模型的哲学：让程序只关注一个目标，并尽可能把它做好，让程序能够互相协同工作完成复杂任务。这才是真正体现CompletableFuture版本实现所具备的巨大优势，用CompletableFuture在代码简洁性、可读性上带来的巨大提升，提高了开发人员进行并发/并行编程的积极性。 CompletableFuture类提供的接口方法还是比较多的，但是这些接口原理上大致相同，理解上也不复杂，关键是要理解这些思想背后的逻辑及它的优势。 Fork/JoinForkJoin框架是在Java 7中引入的，即分支/合并框架，Stream并行流就是依赖ForkJoin将一个操作切分为多个子操作，在多个不同的核上并行地执行这些子操作，所以还是有必要简单认识下。 在ForkJoin框架出来之前，你要将任务拆解进行并发编程： 1、你得明确地把包含数据的数据结构分成若干子部分 2、你要给每个子部分分配一个独立的线程 3、你需要在恰当的时候对它们进行同步来避免不希望出现的竞争条件，等待所有线程完成，最后把这些部分结果合并起来 Java 7引入ForkJoin就是让这些操作更稳定、更不易出错，ForkJoin框架的原理：以递归方式将可以并行的任务拆分成更小的任务，然后将每个子任务的结果合并起来生成整体结果。它是ExecutorService接口的一个实现，它把子任务分配给线程池（称为ForkJoinPool）中的工作线程。 使用ForkJoin框架另一个好处就是：它实现了“工作窃取”机制，这种算法用于在池中的工作线程之间重新分配和平衡任务，直白的说就是：某个线程从其他队列里窃取任务来执行。假如我们需要做一个比较大的任务，我们可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，于是把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应，比如A线程负责处理A队列里的任务。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。 工作窃取算法的优点是充分利用线程进行并行计算，并减少了线程间的竞争，其缺点是在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且消耗了更多的系统资源，比如创建多个线程和多个双端队列。 案例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182ForkJoin框架编程的模板伪代码大致如下： if (任务足够小或不可分) &#123; 顺序计算该任务 &#125; else &#123; 将任务分成两个子任务 递归调用本方法，拆分每个子任务，等待所有子任务完成 合并每个子任务的结果 &#125;你可能已经注意到，这只不过是著名的分递归治算法的并行版本而已。 案例如下：import java.util.concurrent.RecursiveTask;/** * @author 36410 * @Copyright © 2017 tiger Inc. All rights reserved. * @create 2017-12-11 10:27 * Description:你可能已经注意到，这只不过是著名的分治算法的并行版本而已 */public class ForkJoinSumCalculator extends RecursiveTask&lt;Long&gt; &#123; private final long[] numbers; private final int start; private final int end; public static final long THRESHOLD = 10_000; public ForkJoinSumCalculator(long[] numbers) &#123; this(numbers, 0, numbers.length); &#125; private ForkJoinSumCalculator(long[] numbers, int start, int end) &#123; this.numbers = numbers; this.start = start; this.end = end; &#125; @Override protected Long compute() &#123; int length = end - start; if (length &lt;= THRESHOLD) &#123; return computeSequentially(); &#125; /** * 对子任务调用fork方法可以把它排进ForkJoinPool。同时对左边和右边的子任务调用它似乎很自然，但这样做的效率要比直接对其中一个调用compute低。 * 这样做你可以为其中一个子任务重用同一线程，从而避免在线程池中多分配一个任务造成的开销。 * * fork()：放入到ForkJoinPool线程池中执行，compute()重用当前线程执行任务 */ ForkJoinSumCalculator leftTask = new ForkJoinSumCalculator(numbers, start, start + length / 2); leftTask.fork(); ForkJoinSumCalculator rightTask = new ForkJoinSumCalculator(numbers, start + length / 2, end); Long rightResult = rightTask.compute(); Long leftResult = leftTask.join(); return leftResult + rightResult; &#125; private long computeSequentially() &#123; long sum = 0; for (int i = start; i &lt; end; i++) &#123; sum += numbers[i]; &#125; return sum; &#125;&#125;/** * @author 36410 * @Copyright © 2017 tiger Inc. All rights reserved. * @create 2017-12-11 10:30 * Description:Runtime.availableProcessors的返回值来决定线程池使用的线程数。请注意availableProcessors方法虽然看起来是处理器， 但它实际上返回的是可用内核的数量，包括超线程生成的虚拟内核 */public class Main &#123; public static long forkJoinSum(long n) &#123; long[] numbers = LongStream.rangeClosed(1, n).toArray(); ForkJoinTask&lt;Long&gt; task = new ForkJoinSumCalculator(numbers); return new ForkJoinPool().invoke(task); &#125;&#125; 总结Java自上世纪90年代出现，到如今已20多年历史，这期间开发生态已发生了很大的变化，一方面，多核时代让并发/并行编程成为一个必须面临解决的问题；另一方面，非结构化、半结构化数据的大量涌现导致数据处理功能由传统的数据库处理移植到程序开发中需要解决的问题。而这两种潮流的转变都能通过使用函数式编程非常轻松地得到支持，Java 8及时的引入lambda、Stream、CompletableFuture等，将流式数据计算的思想带入了Java 8中，可以说是完成了一次华丽的转型。 到这里为止，对Java 8总结基本要完结了，前面讲了那么多，其核心思想我这里归纳成如下几点： 1、lambda函数式编程是对流式编程思想的一个很好解决方案，反过来，正是流式计算模型的兴起带动了lambda函数式编程近几年的风靡 2、Stream是对流式思想和lambda函数式编程结合进行的一次极佳实践，本质上是将一系列lambda表达式运用流式思想进行组装成一条数据处理链，以完成复杂的任务；同时，Stream带来的声明式编程方式让开发者通过类似描述性语言就可以实现复杂业务逻辑开发，极大的降低了编程的复杂性；总之，Stream让传统的面向“存储”的集合具有了面向“计算”的能力 3、CompletableFuture完成了将并发/并行编程和流式思想相结合的重要创新，再结合lambda函数式编程，很好的解决了并发/并行编程的复杂性导致开发积极性不高、后期维护难等问题，现在通过CompletableFuture可以简洁的实现灵活强大的并发/并行编程，为并发/并行编程成为开发常态提供了强大的技术支持手段 4、一方面，CPU进入多核时代与现有的并发/并行编程不足；另一方面，海量的半结构化、非结构化数据的出现与传统的面向数据库编程(通过关系型数据库提供的丰富的函数完成各种业务数据处理)冲突，Java 8通过流式思想和lambda函数式编程的引入都得以很好的解决了这两个问题 5、总之，Java 8是历年来改变最大一次，但其本质上要实现的目标是将流式计算模型引入，lambda表达式只不过是对这种模型引入提供了一种优雅的解决方案 本文重点不是教你怎么使用lambda、Stream、CompletableFuture等这些Java 8中的新特性，而是希望你能看清这些改变的意义及背后的思想是什么。不要再仅仅认为：这些新特性只是一种很酷炫的技术，也仅仅只是让开发中的一些代码变得简洁，仅此而已。我希望：当你深入了解这些新特性背后的哲学、思想后，应该认识到这就是一种潮流，一种真实需求的体现。 最后用我一个切身感受结束：没有使用Lamdba之前，你可能永远都不想使用它，因为怪异的语法与现有的面向对象编程格格不入，但是当你开始熟悉并深入使用它后，你会迷恋上它。]]></content>
      <categories>
        <category>计算模型</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>计算模型</tag>
        <tag>Java8</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Disruptor之概览]]></title>
    <url>%2F2018%2F01%2F26%2FDisruptor%E4%B9%8B%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[Diruptor概述“多核危机”驱动了并发编程的复兴，然后并发编程和一般的系统相比，复杂性有个很大梯度的上升。多线程开发很大困难在于：多个线程间存在依赖关系时，如何进行协调。依赖一方面是执行顺序的依赖，如某个线程执行需要依赖其他线程执行或其它线程的某些阶段执行结果，Java为我们提供的解决方案是：wait/notify、lock/condition、join、yield、Semaphore、CountDownLatch、CyclicBarrier以及JDK7新增的一个Phaser等；数据依赖主要是多个线程对同一资源并发修改导致的数据状态不一致问题，Java中主要依靠Lock和CAS两种方案，也就是我们熟知的悲观锁、乐观锁。 然而，当你在并发编程方面慢慢有些经验并开始在项目中使用时，你会发现仅仅依赖JDK提供的上面所说开发工具类是远远不够的， JDK提供的工具类都只能解决一个个功能“点”的问题。并发编程复杂性一个体现就是：多个顺序执行流在多核CPU中同时并行执行与我们已经习惯的单个数据顺序流执行的方式产生了很大的冲突。 好比：现在你开车从A地到B地去，传统的开发模式就像从A地到B地之间只存在一条公路，你只需要延着这个公路一直开下去就可以达到B地；假如经过多年发展，现在A地到B地横起有10条公路，纵起有10条公路，它们之间相互交叉形成错综复杂的公路网，你再开车从A地到B地就会存在太多的选择，可能从东南西北任何方向出发最终都能到达B地。这就体现了并发编程和传统编程复杂性的对比：传统编程由于只存在一个顺序执行流，可以很好的预判程序的执行流程；而并发编程存在太多的顺序执行流导致很难准确的预判出它们真正的执行流程，一旦出现问题也很难排查，就好比上面的例子第二种情况，你很难预判你开车的真正路线，而且可能存在每次路线都不一样情况。 我认为一个并发编程项目好坏其中一个关键核心就是：项目的整体结构是否清晰。很简单的一个例子，调用notify()方法唤醒挂起在指定对象上的休眠线程，如果没有一个清晰简单的架构设计，可能会导致在该对象上进行休眠的对象散落到系统中各处代码上，很难把控具体唤醒的是哪个线程从而与你的业务逻辑发生偏差导致bug的出现。当然，项目结构清晰在传统编程中也是非常看重的，只有结构清晰的架构才会让人易于理解，同时和他人沟通探讨时方便描述，但是在并发编程中这点尤为重要，因为并发编程的复杂性更高，没有一个清晰的结构设计，你可能经过大量测试修改暂时做出了一个看似没有bug的项目，但是后期需求变更或者是其他人来维护这个项目时，很难下手导致后期会引入大量的bug，而且不利于项目功能的扩展。 常用的并发编程使用的模型有并行模型、流水线模型、生产者/消费者模型、Actor模型等，采用模型设计一方面是因为这些模型都是大牛们经过长时间实际生产经验的积累总结出的并发编程方面一些好的解决方案；另一方面，采用模型设计可以解决相关人员之间沟通信息不对等问题，降低沟通学习成本。 并行模型是JDK8中Stream所采用的实现并发编程的方式，并行模型非常简单，就是为每个任务分配一个线程直到该任务执行结束，示意图如下： 并行模型太过简单导致对任务的精细化控制不足，一个任务可能会被分解为多个阶段，而每个阶段的子任务特性可能差别很大，这时并行模型就无能为力了。并行模型只适合于CPU密集型且任务中不含IO阻塞等情况的任务。这时，就演进出流水线模型，示意图如下： 流水线模型在实际的并发编程中使用比较常见，我们所说的Pipeline设计模型、Netty框架等都是这一思想的体现。 生产者/消费者模型在并发编程中也是使用频度非常高的一个模型，生产者/消费者模型可以很容易地将生产和消费进行解耦，优化系统整体结构，并且由于存在缓冲区，可以缓解两端性能不匹配的问题。 Actor模型其典型代表就是Akka，基于Akka可以轻松实现一个分布式异步数据处理集群系统，非常强大，后期我们有机会可以再深入讨论下Akka。 好了，说了这么多，终于要开始正题：Disruptor，官方宣传基于该框架构建的系统单线程可以支撑每秒处理600万订单，此框架真乃惊为天人。Disruptor在生产者/消费者模型上获得尽量高的吞吐量和尽量低的延迟，其目标就是在性能优化方面做到极致。国内国外都存在大量的知名项目在广泛使用，比如我们所熟知的strom底层就依赖Disruptor的实现，其在并发、缓存区、生产者/消费者模型、事务处理等方面都存在一些性能优秀的方案，因此是非常值得深入研究的。 生产者/消费者模型生产者/消费者模型在编程中使用频度非常高的一个模型，生产者/消费者模型可以很容易地将生产和消费进行解耦，优化系统整体结构，并且由于存在缓冲区，可以缓解两端性能不匹配的问题。生产者/消费者和我们所熟悉的设计模式中的观察者模型很相似，生产者类似于被观察者，消费者类似于观察者，被观察者的任何变动都以事件的方式通知到观察者；同理，生产者生产的数据都要传递给消费者最终都要被消费者处理。 一般项目开发中，我们可以使用JDK提供的阻塞队列BlockingQueue很简单的实现一个生产者/消费者模型，其中生产者线程负责提交需求，消费者线程负责处理任务，二者之间通过共享内存缓冲区进行通信。 BlockingQueue实现类主要有两个：ArrayBlockingQueue和LinkedBlockingQueue，底层实现一个是基于数组的，一个是基于链表的，这种实现方式的差异导致了它们使用场景的不一样。在生产者/消费者模型中的缓存设计上肯定优先使用ArrayBlockingQueue，但是查看ArrayBlockingQueue底层源码会发现，读写操作通过重入锁实现同步，而且读写操作使用的是同一把锁，并没有实现读写锁分离；另外，锁本身的成本还是比较高的，锁容易导致线程上下文频繁的发生切换，了解CPU核存储硬件架构的可能会知道，每核CPU都会存在一个独享的高速缓存L1，假如线程切换到其它CPU上执行会导致之前CPU高速缓存L1中的数据不能再被使用，降低了高速缓存使用效率。因此，在高并发场景下，性能不是很优越。 12345678910111213141516171819202122232425//向Queue中写入数据public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly();//可中断方式获取锁，实现同步 try &#123; while (count == items.length) notFull.await(); insert(e); &#125; finally &#123; lock.unlock(); &#125;&#125;//从Queue中取出数据public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly();//可中断方式获取锁，实现同步 try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; Disruptor消息生产模型 Producer生产出一个消息事件Event，需要放入到RingBuffer中，流程大致如下： ​ 1、首先调用Sequencer.next()方法，获取RingBuffer上可用的序号用于将新生成的消息事件放入； ​ 2、Sequencer首先对nextValue+1代表当前需要申请的RingBuffer序号(nextValue标记了之前已经申请过的序号,nextValue+1就是下一个可申请的序号)，但是nextValue+1指向的RingBuffer槽位存放的消息可能并没有被消费，如果直接返回这个序号给生产者，就会导致生产一方将该槽位的消息事件重新填充覆盖导致之前数据丢失，这里就需要一个判断：判断申请的RingBuffer序号代表的槽位之前的消息事件是否已被消费，判断逻辑如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public long next(int n) &#123; if (n &lt; 1) //n表示此次生产者期望获取多少个序号，通常是1 &#123; throw new IllegalArgumentException("n must be &gt; 0"); &#125; long nextValue = this.nextValue; //这里n一般是1，代表申请1个可用槽位，nextValue+n就代表了期望申请的可用槽位序号 long nextSequence = nextValue + n; //减掉RingBuffer的bufferSize值，用于判断是否出现‘绕圈覆盖’ long wrapPoint = nextSequence - bufferSize; //cachedValue缓存之前获取的最慢消费者消费到的槽位序号 long cachedGatingSequence = this.cachedValue; //如果申请槽位序号-bufferSize比最慢消费者序号还大，代表生产者绕了一圈后又追赶上了消费者，这时候就不能继续生产了，否则把消费者还没消费的消息事件覆盖 if (wrapPoint &gt; cachedGatingSequence || cachedGatingSequence &gt; nextValue) &#123; /** cursor代表当前已经生产完成的序号，了解多线程可见性可能会知道： 1、CPU和内存间速度不匹配，硬件架构上一般会在内存和CPU间还会存在L1、L2、L3三级缓存 2、特别是L1高速缓存是CPU间相互独立不能共享的，线程操作可以看着基于L1缓存进行操作，就会导致线程间修改不会立即被其它线程感知，只有L1缓存的修改写入到主存然后其它线程将主存修改刷新到自己的L1缓存，这时线程1的修改才会被其它线程感知到 3、线程修改对其它线程不能立即可见特别是在高并发下可能会带来些问题，JAVA中使用volatile可以解决可见性问题 4、这里就是采用UNSAFE.putLongVolatile()插入一个StoreLoad内存屏障，具体可见JMM模型，主要保证cursor的真实值对所有的消费线程可见，避免不可见下消费线程无法消费问题 */ cursor.setVolatile(nextValue); long minSequence; //Util.getMinimumSequence(gatingSequences, nextValue)获取当前时刻所有消费线程中，消费最慢的序号 //上面说过cachedValue是缓存的消费者最慢的序号 //这样做目的：每次都去获取真实的最慢消费线程序号比较浪费资源，而是获取一批可用序号后，生产者只有使用完后，才继续获取当前最慢消费线程最小序号，重新获取最新资源 while (wrapPoint &gt; (minSequence = Util.getMinimumSequence(gatingSequences, nextValue))) &#123; //如果获取最新最慢消费线程最小序号后，依然没有可用资源，做两件事： // 1、唤醒waitStrategy上所有休眠线程，这里即是消费线程(避免因消费线程休眠而无法消费消息事件导致生产线程一直获取不到资源情况) // 2、自旋休眠1纳秒 //可以看到，next()方法是一个阻塞接口，如果一直获取不到可用资源，就会一直阻塞在这里 waitStrategy.signalAllWhenBlocking(); LockSupport.parkNanos(1L); &#125; //有可用资源时，将当前最慢消费线程序号缓存到cachedValue中，下次再申请时就可不必再进入if块中获取真实的最慢消费线程序号，只有这次获取到的被生产者使用完才会继续进入if块 this.cachedValue = minSequence; &#125; //申请成功，将nextValue重新设置，下次再申请时继续在该值基础上申请 this.nextValue = nextSequence; //返回申请到RingBuffer序号 return nextSequence; &#125; ​ 3、申请到可用序号后，提取RingBuffer中该序号中的Event，并重置Event状态为当前最新事件状态 ​ 4、重置完成后，调用Sequencer.publish()提交序号，提交序号主要就是修改cursor值，cursor标记已经生产完成序号，这样消费线程就可以来消费事件了 12345678@Overridepublic void publish(long sequence)&#123; //修改cursor序号，消费者就可以进行消费 cursor.set(sequence); //唤醒消费线程，比如消费线程消息到无可用消息时可能会进入休眠状态，当放入新消息就需要唤醒休眠的消费线程 waitStrategy.signalAllWhenBlocking();&#125; 总结：消息事件生产主要包含三个步骤： ​ 1、申请序号：表示从RingBuffer上获取可用的资源 ​ 2、填充事件：表示获取到RingBuffer上可用资源后，将新事件放入到该资源对应的槽位上 ​ 3、提交序号：表示第二部新事件放入到RingBuffer槽位全部完成，提交序号可供消费线程开始消费 Disruptor消息处理模型 消息处理端需要从RingBuffer中提取可用的消息事件，并注入到用户的业务逻辑中进行处理，流程大致如下： ​ 1、消费端核心类是EventProcessor，它实现了Runnable接口，Disruptor在启动的时候会将所有注册上来的EventProcessor提交到线程池中执行，因此，一个EventProcessor可以看着一个独立的线程流用于处理RingBuffer上的数据 ​ 2、EventProcessor通过调用SequenceBarrier.waitFor()方法获取可用消息事件的序号，其实SequenceBarrier内部还是调用WaitStrategy.waitFor()方法，WaitStrategy等待策略主要封装如果获取消息时没有可用消息时如何处理的逻辑信息，是自旋、休眠、直接返回等，不同场景需要使用不同策略才能实现最佳的性能 12345678910111213141516171819202122232425262728293031323334ProcessingSequenceBarrier： WaitStrategy waitStrategy; Sequence dependentSequence; boolean alerted = false; Sequence cursorSequence;//可供消费消息的sequence Sequencer sequencer;ProcessingSequenceBarrier中核心方法只有一个：waitFor(long sequence)，传入希望消费得到起始序号，返回值代表可用于消费处理的序号，一般返回可用序号&gt;=sequence，但也不一定，具体看WaitStrategy实现/** * 总结： * 1、sequence：EventProcessor传入的需要进行消费的起始sequence * 2、这里并不保证返回值availableSequence一定等于given sequence，他们的大小关系取决于采用的WaitStrategy * a.YieldingWaitStrategy在自旋100次尝试后，会直接返回dependentSequence的最小seq，这时并不保证返回值&gt;=given sequence * b.BlockingWaitStrategy则会阻塞等待given sequence可用为止，可用并不是说availableSequence == given sequence，而应当是指 &gt;= * c.SleepingWaitStrategy:首选会自旋100次，然后执行100次Thread.yield()，还是不行则LockSupport.parkNanos(1L)直到availableSequence &gt;= given sequence */ @Override public long waitFor(final long sequence) throws AlertException, InterruptedException, TimeoutException &#123; checkAlert(); //调用WaitStrategy获取RingBuffer上可用消息序号，无可消费消息是该接口可能会阻塞，具体逻辑由WaitStrategy实现 long availableSequence = waitStrategy.waitFor(sequence, cursorSequence, dependentSequence, this); if (availableSequence &lt; sequence) &#123; return availableSequence; &#125; //获取消费者可以消费的最大的可用序号，支持批处理效应，提升处理效率。 //当availableSequence &gt; sequence时，需要遍历 sequence --&gt; availableSequence，找到最前一个准备就绪，可以被消费的event对应的seq。 //最小值为：sequence-1 return sequencer.getHighestPublishedSequence(sequence, availableSequence); &#125; ​ 3、通过waitFor()返回的是一批可用消息的序号，比如申请消费7好槽位，waitFor()返回的可能是8表示从6到8这一批数据都已生产完毕可以进行消费 ​ 4、EventProcessor按照顺序从RingBuffer中取出消息事件，然后调用EventHandler.onEvent()触发用户的业务逻辑进行消息处理 1234567891011121314151617181920212223while (true) &#123; try &#123; //读取可消费消息序号 final long availableSequence = sequenceBarrier.waitFor(nextSequence); if (batchStartAware != null) &#123; batchStartAware.onBatchStart(availableSequence - nextSequence + 1); &#125; while (nextSequence &lt;= availableSequence) &#123; //循环提取所有可供消费的消息事件 event = dataProvider.get(nextSequence); //将提取的消息事件注入到封装用户业务逻辑的Handler中 eventHandler.onEvent(event, nextSequence, nextSequence == availableSequence); nextSequence++; &#125; sequence.set(availableSequence); &#125; &#125;&#125; ​ 5、当这批次的消息处理完成后，继续重复上面操作调用waitFor()继续获取可用的消息序号，周而复始 好了，这节主要对Disruptor的生产模型和消费模型进行了一个简单的介绍，后面会逐渐对Disruptor涉及到的每个核心组件进行分析，了解它们优秀的设计思想。]]></content>
      <categories>
        <category>Disruptor</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>计算模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时区总结]]></title>
    <url>%2F2018%2F01%2F20%2F%E6%97%B6%E5%8C%BA%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[最近工作上涉及到些时区概念，在同事交流过程中顺便总结了下。 时区下面用如下系统结构介绍下时区概念： 1、现在前端WEB需要获取到当前时间:new Date() ，new Date()创建时间代表当前时刻，是不涉及到任何时区问题的，Date类型的API中也没有任何和时区进行关联的方法，Date可以代表对时间戳long的一个封装，表示一个瞬时时刻，Date.getTime()方法就可以获取到当前封装的时间戳值，同理也可以通过new Date(时间戳)来创建一个时间，比如当前时间戳：1514966524591L 2、现在要把这个获取到的new Date()传递到服务A中，假如使用常用到的REST接口进行传递，我们知道REST是通过Json字符串传递参数的，这就涉及到Date到字符串转换的问题了，要用到SimpleDateFormat时间格式化类： 1234SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS");System.out.println(dateFormat.format(date));输出如下：2018-01-03 16:02:04.591 由于时间格式化时没有指定时区，默认采用当前系统时区，所以这个输出就代表：北京时间(东八区)2018-01-03 16:02:04.591。当然现在框架都是集成了Json转换工具类，你不需要像我这里自己创建SimpleDateFormat然后指定时区，但原理都是一样的，一般框架将Date转成Json对象都是会提供设置时区的接口的。 如果和服务A约定使用UTF零时区而不是使用本地时区呢，因为使用本地时区存可能会存在问题，假如WEB服务部署到东九区而不是东八区，这样使用SimpleDateFormat解析new Date()使用的是东九区时区，服务A收到了可能依然会认为是东八区，这样服务A解析传递过来的时间字符串就会存在问题。WEB服务和服务A就可以约定传递使用UTF时区，保证就不会出现问题，但是WEB在将Date转成String的时候需要指定UTF时区，不能再使用默认的系统本地时区了，如下： 12345SimpleDateFormat dateFormat2 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS");dateFormat.setTimeZone(TimeZone.getTimeZone("GMT"));//指定为UTF时区System.out.println(dateFormat.format(date));输出如下：2018-01-03 08:02:04.591 发现比之前的2018-01-03 16:02:04.591少了8个小时，这就体现了同一个时间，在不同时区代表的具体时间，即几月几日，几点几分是不一样的，但是东八区的2018-01-03 16:02:04.591和UTF时区的2018-01-03 08:02:04.591代表的是同一个时间，即同一时刻。 3、服务A接收到2018-01-03 16:02:04.591这个代表时间的字符串，需要将其转成成Date类型，它就需要知道这个时间字符串到底代表那个时区的，当然如果服务A本身就是运行在东八区就不需要指定时区(默认和系统时区保持一致)，否则解析的时候就需要指定具体的时区： 1234567String timeStr = "2018-01-03 16:02:04.591";SimpleDateFormat dateFormat2 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS");dateFormat2.setTimeZone(TimeZone.getTimeZone("GMT+8:00"));Date date2 = dateFormat2.parse(timeStr);System.out.println(date2.getTime());输出：1514966524591(和WEB传入的Date的时间戳一致，即传递过程正常) 如果WEB传递过来的是UTF时区时间：2018-01-03 08:02:04.591，服务A解析如下：1234567String timeStr = "2018-01-03 08:02:04.591";SimpleDateFormat dateFormat3 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS");dateFormat3.setTimeZone(TimeZone.getTimeZone("GMT"));//指定用UTF时区解析时间Date date3 = dateFormat3.parse(timeStr);System.out.println(date3.getTime());输出：1514966524591(和WEB传入的Date的时间戳一致，即传递过程正常) 总结：如果系统间时区不一致，或者约定传递时间用UTF时间格式，就要保证两个方面： 1、传递方在将Date解析成字符串时指定时区为UTF 2、接收方在接收到时间字符串进行解析成Date类型时，也需要指定时区为UTF 3、如果不指定都会采用系统默认时区，可能就会存在问题 4、服务A正常解析出WEB传递过来的时间后，写入到数据库表中的一个字段中，如果字段类型是datetime，插入数据是不受任何时区影响的(包括服务本地时区、MySQL运行服务器时区及MySQL自己时区)，这就是Date代表的时间至少时间戳的封装，相当于一个long型，时间戳是没有时区概念的。 123456789查看数据库时区：show variables like "%time_zone%";+------------------+--------+| Variable_name | Value |+------------------+--------+| system_time_zone | CST || time_zone | SYSTEM |+------------------+--------+2 rows in set (0.00 sec) time_zone说明mysql使用system的时区，system_time_zone说明system使用CST时区，CST时区在这里就代表的是北京东八区时区、 但是这里要注意下：你使用select查询的时候，其实是存在数据库中Date类型到字符串转换的过程，因为你使用select查询看到的时间一般都是“2017-10-1 12:00:00”等这种格式，这就是数据库时区的作用，同理，如果数据库字段是datetime，你insert时指定的是“2017-10-1 12:00:00”等这种数据，数据库也是会存在上面说的字符串转成Date要涉及到时区，这里使用的也是数据库时区，其实更上面介绍的Date传递原理是一致的。如果你把数据库时区修改了，select查询出来同样的数据，展示的时间字符串是不一样的，就是这个道理。 5、服务B从数据库查询，查询出来的是一个Date类型，这里是不会涉及到任何时区问题。可能经常会出现下面一种情况： 12341、客户端1从数据库查询该数据看到的是2018-01-03 16:02:04.591，因为没有指定时区默认使用的是本地时区，假设为东八区2、客户端2从数据库查询拿到同样的数据，但是输出的确是2018-01-03 08:02:04.591，因为客户端本地系统时区为UTF时区3、虽然客户端1和客户端2看到像是不同的时间，但是它们拿到的是同一份数据，指向的时间也是同一个时刻的时间，即这一个时间时刻在不同时区有不同的表示，但是代表的时间都是同一个时刻4、如果需要统一时区，需要向之前样式，转换时指定时区即可 ​ 总结计算机中的时间都是通过时间戳表示的，如程序中的Date类型、数据库中的Date类型，其内部就是对时间戳的一个封装，时间戳没有时区概念，所以在计算机中的时间是没有时区概念的。 那么为什么会有时区概念呢？时区存在主要是为了：自然时间表示时必须要有时区才有意义，否则时间是没有意义的。自然时间就是现实生活中人们所认识的时间，计算机中的时间是时间戳，在现实生活中肯定是不方便理解的，现实生活中我们还是更倾向使用”2018-01-20 18:00:00”这种自然时间，但是这个时间表示是有问题的：到底是哪个时区的1月20号18点呢？ 时间的概念更倾向于时刻，它是全世界唯一的，比如现在这个时刻东八区北京时间是：2018-1-25 15:30:30，其对应的时间戳是1516865430404，但是同样这刻在零时区时间是：2018-1-25 07:30:30，但是它的时间戳依然是1516865430404，也就是说，计算机中的时间戳是一个时刻的概念，不存在时区区别，但是当这个时刻表示为自然时间时就存在不同时区表示方法不一样了。 综上来看，我们在程序开发中，当存在”2018-01-20 18:00:00”解析为Date类型，或Date类型格式化为”2018-01-20 18:00:00”，即计算机时间和自然时间相互转换时，就一定要注意时区，这是因为当出现”2018-01-20 18:00:00”必须带有时区才有意义。 在平时开发中，如果多系统间需要传递时间，最近实践是采用时间戳传递而不是”2018-01-20 18:00:00”这种时间格式传递，原因如下：​ 1、时间戳占用的字节大小比2018-01-03 16:02:04.591小很多，在系统间传递网络带宽更有优势；​ 2、当然最主要的还是：时间戳不存在时区概念，不需要进行转换，而2018-01-03 16:02:04.591格式在传递时进行转换非常容易引起混乱导致错误​ 3、数据库中的时间类型采用long型时间戳，效率更高]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F01%2F10%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
</search>
